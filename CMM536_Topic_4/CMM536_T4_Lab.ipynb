{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosfmorenog/CMM536/blob/master/CMM536_Topic_4/CMM536_T4_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amzKVQw2Gn_d"
      },
      "source": [
        "# CMM536 Topic 4 Laboratory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se5WZaRgGn_i"
      },
      "source": [
        "In this activity you will use a database of **\"features extracted\"** to perform different types of classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjYreTdIGn_k"
      },
      "source": [
        "## Installing the necessary packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PTMV3cRGn_m"
      },
      "source": [
        "We will use `sklearn` and `scipy` for this activity. If you don't have these packages already, run the cell bellow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6Sdk1GnGn_n"
      },
      "outputs": [],
      "source": [
        "!pip install sklearn\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imY37mBAGn_p"
      },
      "source": [
        "## Loading the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zksd8_rFGn_r"
      },
      "source": [
        "We will use the `IRIS` database, which contains 150 samples of the sepal and petal lengths and widths from 3 different iris flower species: Setosa, Versicolor and Virginica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QV-7lAGGn_r"
      },
      "source": [
        "![Fig 1: Iris dataset.](https://www.dropbox.com/s/kqgsr9tmjdgou4g/iris.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mknBo6-lGn_t"
      },
      "source": [
        "This dataset is already available in Python by importing the `sklearn.datasets` function and using the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUM-ji_CGn_v"
      },
      "outputs": [],
      "source": [
        "## Load iris dataset\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvvxwTdMGn_x"
      },
      "source": [
        "Notice that we will **NOT** work with the actual images, but rather with the numerical information extracted from some real flower samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDjNSeFAGn_y"
      },
      "source": [
        "In fact, this dataset was presented in 1936 by a statistician called Ronald Fisher, and thus we don't even have access to the original images to extract some proper feature from!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmVeK97fGn_y"
      },
      "source": [
        "The dataset is contained on a **dictionary-like** structure referred to as **sklearn.utils.Bunch**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "mWh5IZuQGn_z"
      },
      "outputs": [],
      "source": [
        "type(iris)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzJFRHi3Gn_0"
      },
      "source": [
        "If you print this dataset, you will see a lot of things contained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "sap-CTQ1Gn_0"
      },
      "outputs": [],
      "source": [
        "print(iris)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTvh9kb9Gn_1"
      },
      "source": [
        "Therefore, we need to extract each index of this dictionary into a different variables to understand and analyse them separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQytxeRqGn_2"
      },
      "source": [
        "First, we will import the `features` into a variable called `data`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lRSHUpDGn_2"
      },
      "outputs": [],
      "source": [
        "data = iris['data']\n",
        "print(data)\n",
        "print(type(data))\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJtdvp9UGn_2"
      },
      "source": [
        "The data is stored in a `numpy array` of 150 rows and 4 columns, each corresponding to the  measurements of a flower."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWWoh2LNGn_2"
      },
      "source": [
        "Then, we will import the `headers` of the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yrs3nvweGn_3"
      },
      "outputs": [],
      "source": [
        "header = iris['feature_names']\n",
        "print(header, type(header))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aszyWcyrGn_3"
      },
      "source": [
        "**Why do you think the features and the header are stored separately?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eWHq9NVGn_4"
      },
      "source": [
        "**YOUR Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfoDK1vGn_4"
      },
      "source": [
        "Afterwards, we will import the **class/target**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2tGCbkDGn_4"
      },
      "outputs": [],
      "source": [
        "target = iris['target']\n",
        "print(target, type(target), target.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koUOZZ_AGn_5"
      },
      "source": [
        "The class/target is a `numpy array` which contains the **category** of each flowers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wzVWNaCGn_5"
      },
      "source": [
        "Each sample is labelled as $0$, $1$ or $2$ instead of the iris type since the labels can be better used as numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjgsAAQzGn_5"
      },
      "source": [
        "A separate key called **target_names** contains the name corresponding to each numerical label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "QRrDLbwtGn_6"
      },
      "outputs": [],
      "source": [
        "target_names = iris['target_names']\n",
        "print(target_names, type(target_names), target_names.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL1NRhptGn_6"
      },
      "source": [
        "**Why do you think the target and the target names are stored separately?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8GXdJIFGn_6"
      },
      "source": [
        "**YOUR Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB5Um28hGn_6"
      },
      "source": [
        "In fact, We can use `list comprehension` to obtain a list of names instead of numerical labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtXhLCPFGn_7"
      },
      "outputs": [],
      "source": [
        "# Create a variable called \"target_named\" and store the actual categories\n",
        "target_named = [target_names[t] for t in target]\n",
        "print(target_named)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tcNw8KQGn_7"
      },
      "source": [
        "Finally, just in case you are interested, there is an entry called `DESC` containing the description of the dataset (a string):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "5DOkGUIZGn_7"
      },
      "outputs": [],
      "source": [
        "iris['DESCR']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naoBrPl_Gn_8"
      },
      "source": [
        "## Visualising the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOX3gJXlGn_8"
      },
      "source": [
        "Run the following code and analyse the output (If instead of a 3D chart you receive a `matplotlib` message, just run the cell again)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvKqyRr0Gn_9"
      },
      "outputs": [],
      "source": [
        "## Plot the ground truth data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "fig = plt.figure(1, figsize=(4, 3))\n",
        "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
        "for name, label in [('Setosa', 0),('Versicolor', 1),('Virginica', 2)]:\n",
        "    ax.text3D(data[target == label, 3].mean(),\n",
        "              data[target == label, 0].mean(),\n",
        "              data[target == label, 2].mean() + 2, name,\n",
        "              horizontalalignment='center',\n",
        "              bbox=dict(alpha=.2, edgecolor='w', facecolor='w'))\n",
        "ax.scatter(data[:, 3],data[:, 0],data[:, 2],c=target.astype(np.float),edgecolor='k')\n",
        "ax.w_xaxis.set_ticklabels([])\n",
        "ax.w_yaxis.set_ticklabels([])\n",
        "ax.w_zaxis.set_ticklabels([])\n",
        "ax.set_xlabel('Petal width')\n",
        "ax.set_ylabel('Sepal length')\n",
        "ax.set_zlabel('Petal length')\n",
        "ax.set_title('Original Iris Dataset')\n",
        "ax.dist = 12\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jryWrYpsGn_-"
      },
      "source": [
        "We can see that the features of the Setosas are notably distinct to the other two types. Therefore, we would expect that a machine learning algorithm is at least capable of identifying all Setosas correctly!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvzRJR4WGn_-"
      },
      "source": [
        "## Unsupervised Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynD84WOMGn__"
      },
      "source": [
        "Considering only the features and ignoring the target, we will use an algorithm called **K-means** to **cluster** the 150 iris samples into $k=3$ clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PluNifE2Gn__"
      },
      "source": [
        "* **NOTE:** When testing unsupervised learning, there is no need to split our dataset into training/validation/testing as we are ignoring our labels, therefore the expected output is compared against the actual labels of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoRq6-5zGn__"
      },
      "source": [
        "To use this algorithm, we can import the function `Kmeans` from the `sklearn` module and execute it using the following input parameters (the explanation of the parameters can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DSBaX2gGoAA"
      },
      "outputs": [],
      "source": [
        "## Clustering data using K-means\n",
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=3, init='k-means++', n_init=1, max_iter=300, \n",
        "                tol=0.0001, precompute_distances='auto', random_state = 0,\n",
        "                n_jobs=1, algorithm='auto').fit(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ3gUunAGoAA"
      },
      "source": [
        "We then store the result of the training in a variable called `kmeans`, which contains the information of how these features can be grouped (i.e. clustered)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPxuJjmqGoAB"
      },
      "source": [
        " We can visualise the resulting target by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77cfqbYMGoAB"
      },
      "outputs": [],
      "source": [
        "# Visualise the target learned by the unsupervised classification algorithm\n",
        "target_kmeans = kmeans.labels_\n",
        "print(target_kmeans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxesr960GoAC"
      },
      "source": [
        "A similar code as the one used to visualise the original dataset can be used to plot the clustered data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO58_JSkGoAC"
      },
      "source": [
        "Notice that this time we will not use the target names, as clustering algorithms can only find a pattern in the data and separate it into groups:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkMW6bkIGoAC"
      },
      "outputs": [],
      "source": [
        "## Plot the results of K-means clustering\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "fig = plt.figure(1, figsize=(4, 3))\n",
        "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
        "for name, label in [('0', 0),('1', 1),('2', 2)]:\n",
        "    ax.text3D(data[target_kmeans == label, 3].mean(),\n",
        "              data[target_kmeans == label, 0].mean(),\n",
        "              data[target_kmeans == label, 2].mean() + 2, name,\n",
        "              horizontalalignment='center',\n",
        "              bbox=dict(alpha=.2, edgecolor='w', facecolor='w'))\n",
        "ax.scatter(data[:, 3],data[:, 0],data[:, 2],c=target_kmeans.astype(np.float),edgecolor='k')\n",
        "ax.w_xaxis.set_ticklabels([])\n",
        "ax.w_yaxis.set_ticklabels([])\n",
        "ax.w_zaxis.set_ticklabels([])\n",
        "ax.set_xlabel('Petal width')\n",
        "ax.set_ylabel('Sepal length')\n",
        "ax.set_zlabel('Petal length')\n",
        "ax.set_title('K-means (n_cluster=3)')\n",
        "ax.dist = 12\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEaVz8fGGoAD"
      },
      "source": [
        "If we visualy copare both graphs, it appears that the clustering algorithm has clustered setosas as 0, versicolors as 2 and virginicas as 1, however in the original dataset versicolors and virgincas label numbers are opposite!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgrDlcb2GoAD"
      },
      "source": [
        "If we want to compare the similarity between the target obtained using the `K-means` algorithm with respect to the `ground truth`, first we need to exchanged labels \"1\" and \"2\" in `target_kmeans`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqHoPdJ0GoAD"
      },
      "outputs": [],
      "source": [
        "## Exchange labels 1 and 2 in the target obtained using K-means\n",
        "for i, label in enumerate(target_kmeans):\n",
        "    if label==0:\n",
        "        pass\n",
        "    elif label==1:\n",
        "        target_kmeans[i]=2\n",
        "    elif label==2:\n",
        "        target_kmeans[i]=1\n",
        "print(target_kmeans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv6bFvqwGoAE"
      },
      "source": [
        "Now we can compare the two lists by simply using the comparison operation sign and printing the outcome (we will also save it in a variable called `comparison` for future use):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwLHAGJRGoAE"
      },
      "outputs": [],
      "source": [
        "## Comparison of targets\n",
        "comparison = target_kmeans == target\n",
        "print(comparison)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKyIVjuQGoAE"
      },
      "source": [
        "To know the **accuracy** of clustering each iris category, we can count and print in groups of 50 the comparisons:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQtucZniGoAE"
      },
      "outputs": [],
      "source": [
        "# Verify the accuracy of clustering each iris category\n",
        "print('Setosa', comparison[:50],'Accuracy', sum(comparison[:50])/len(comparison[:50]))\n",
        "print('Versicolor', comparison[50:100],'Accuracy', sum(comparison[50:100])/len(comparison[50:100]))\n",
        "print('Virginica', comparison[100:],'Accuracy', sum(comparison[100:])/len(comparison[100:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYH67dl0GoAF"
      },
      "source": [
        "As expected, the Setosa type was easier to cluster compared to the other two types, whereas the Virginicas are harder to cluster!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOGUfQXmGoAF"
      },
      "source": [
        "## Splitting the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp_WKXQgGoAF"
      },
      "source": [
        "As mentioned previously, in unsupervised machine learning you can use your entire dataset to build the model, as the output can be compared with the ground truth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dAvonG2GoAF"
      },
      "source": [
        "If you do the same with a supervised machine learning model, you run the risk of **overfitting/overgeneralising** your model and obtaining something that just works for your samples, but not for new ones!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9U11mygGoAG"
      },
      "source": [
        "Therefore, the first thing we need to do is split the dataset in to `training` and `testing` data. For this activity, you are required to reserve **80% of the data for training** and **20% of the data for testing**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHLqgfnTGoAG"
      },
      "source": [
        "You can either create your own code to do this division or use a function available elsewhere, just **make sure that samples of the three classes of iris flowers are present on both training and testing data!**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TUDgMIwGoAG"
      },
      "outputs": [],
      "source": [
        "## Use the following cell to split your dataset into training and testing\n",
        "## Hint: Explore the train_test_split() function in sklearn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhLAIiMeGoAG"
      },
      "source": [
        "How would you modify your code to ensure that in both datasets there is a balanced number of samples (i.e. 40/40/40 on `training` and 10/10/10 on `testing`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIAgKbUwGoAH"
      },
      "outputs": [],
      "source": [
        "## Use the following cell to split your dataset into training and testing guaranteeing balance\n",
        "## Hint: Investigate about stratification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ited6wYFGoAH"
      },
      "source": [
        "## Supervised Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WujLnBR8GoAH"
      },
      "source": [
        "We will build a SVM classifier using the training data and testing it in the test data. To do so, you need to import `SCV` from the `sklearn.svm` module:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKR5c3Z1GoAH"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58RIXWiwGoAI"
      },
      "source": [
        "Now we will train a SVM model with a linear kernel (more information about what this means can be found [here](https://towardsdatascience.com/support-vector-machine-python-example-d67d9b63f1c8)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46v6mH-XGoAI"
      },
      "outputs": [],
      "source": [
        "model = SVC(kernel='linear')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI5z0fD1GoAI"
      },
      "source": [
        "Then, we need to **fit** our model and store the result in a variable called `clf`. **FOR VISUALISATION PURPOSES, WE WILL ONLY TRAIN USING THE FIRST TWO FEATURES OF THE DATASET**, which are `sepal length` and `sepal width`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZsT9ueXGoAI"
      },
      "outputs": [],
      "source": [
        "# trainng the classifier only using the first two columns of the training data\n",
        "clf = model.fit(X_train[:,0:2],y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq8BAcc0GoAJ"
      },
      "source": [
        "To visualise how our model will be capable to classify test samples into the different categories, let's plot the **decision boundary surface of our model**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvoPIXAjGoAJ"
      },
      "source": [
        "To do so, we need to define two functions: \n",
        "* `make_meshgrid`: This function will create a mesh object for the minimum and maximum objects.\n",
        "* `plot_contours`: This function will learn how to extract the contours of `clf`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P36GMgdfGoAJ"
      },
      "outputs": [],
      "source": [
        "def make_meshgrid(x, y, h=.02):\n",
        "    x_min, x_max = x.min() - 1, x.max() + 1\n",
        "    y_min, y_max = y.min() - 1, y.max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    return xx, yy\n",
        "\n",
        "def plot_contours(ax, clf, xx, yy, **params):\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    out = ax.contourf(xx, yy, Z, **params)\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIqfZbaWGoAK"
      },
      "source": [
        "We can now create a plot with the mesh grid and the contours using the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyJUaWwxGoAK"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "title = ('Decision surface of linear SVC')\n",
        "# To create the mesh grid we use the first and second column\n",
        "xx, yy = make_meshgrid(X_train[:, 0],X_train[:, 1])\n",
        "plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax.scatter(X_train[:, 0],X_train[:, 1], c=y_train, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
        "\n",
        "ax.set_xlabel('Sepal Length')\n",
        "ax.set_ylabel('Sepal Width')\n",
        "\n",
        "ax.set_xticks(())\n",
        "ax.set_yticks(())\n",
        "ax.set_title(title)\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDtEKa-ZGoAK"
      },
      "source": [
        "To test our model on the `test` data, we will **predict** it. **Keep in mind that since we trained with only two features, we should also test with the same two features as well**!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HC2Qnc49GoAK"
      },
      "outputs": [],
      "source": [
        "y_predicted = model.predict(X_test[:,0:2])\n",
        "print(y_predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeNHEpSBGoAL"
      },
      "source": [
        "Finally, we can compare the **model's accuracy** of the obtained labels in `y_predicted` against the ground truth in `y_test`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfeL7qgTGoAL"
      },
      "outputs": [],
      "source": [
        "## Print model's accuracy\n",
        "comparison = y_predicted == y_test\n",
        "print('Accuracy', sum(comparison)/len(comparison))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9EhjhaCGoAL"
      },
      "source": [
        "How would you print the accuracy for each class?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfTdcXAaGoAL"
      },
      "outputs": [],
      "source": [
        "## Use this cell to print the accuracy for each class\n",
        "## Hint: Use the numpy.where() function to find where does a vector have a certain value i.e. 0/1/2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYZ6Ib9wGoAM"
      },
      "source": [
        "## Bonus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3eRpkSBGoAM"
      },
      "source": [
        "* Try to use different combinations of training/testing split, features used in the model, parameter, etc. Does the accuracy of your model improve? Is it better or worse compared to **Kmeans**?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytde1OscGoAM"
      },
      "source": [
        "* Check out how different kernel types affect the performance of the SVM classifier [here](https://scikit-learn.org/0.18/auto_examples/svm/plot_iris.html). Would you consider using a different kernel for this classifier?"
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "CMM536_T4_Lab.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}