{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosfmorenog/CMM536/blob/master/CMM536_Topic_8/CMM536_T8_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-cM3kv_ceM_"
      },
      "source": [
        "# Topic 8 Lab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6touOOGceNC"
      },
      "source": [
        "Now that you know the basis of a CNN, you will run one of them in very few lines of code! To do so, we will use `Keras` with a `Tensorflow` backend, along with the very popular `mnist` dataset of handwritten numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOSJ2tBqceND"
      },
      "source": [
        "First, install the necessary packages if you don't have them already:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xw8k98qxceNE"
      },
      "outputs": [],
      "source": [
        "# 0. Installing the necesssary packages\n",
        "!pip install keras\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn16WyqWceNG"
      },
      "source": [
        "Then we will ensure that `Keras` uses `Tensorflow` as backend. Notice that if you prefer to use another backend such as `Theano`, you simply need to change the name in the second line of the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5eWUu0XceNH"
      },
      "outputs": [],
      "source": [
        "# 1. Ensure you are using Theano backend\n",
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2Crn-ZWceNJ"
      },
      "source": [
        "Now you will import the necessary packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtSABBJTceNK"
      },
      "outputs": [],
      "source": [
        "# 2. Import libraries and modules\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zenSq4GwceNL"
      },
      "source": [
        "Then, we will set a **random seed** to be able to repeat the results and get the same results every time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_dgrw6MceNM"
      },
      "outputs": [],
      "source": [
        "# 3. Set random seed (for reproducibility)\n",
        "np.random.seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy3e5-y8ceNO"
      },
      "source": [
        "With the following cell you will download the data from the `mnist` dataset. Notice that the data comes already partitioned in test and training sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHyOv0zWceNS"
      },
      "outputs": [],
      "source": [
        "# 4. Load pre-shuffled MNIST data into train and test sets\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R6aB65FceNT"
      },
      "source": [
        "Let's check the shape of the things obtained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKSSaWVXceNV"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XywPvG_sceNV"
      },
      "source": [
        "Notice that we have 60'000 samples for training and 10'000 for testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35IGUJsiceNV"
      },
      "source": [
        "Now we will preprocess the data to be used by the classifier. To be able to use Keras, we need to do the following:\n",
        "1. **Reshape** the data into **four** dimensions i.e. the training set will be of shape (60000,28,28,1) and the test set of (10000,28,28). This is useful since the network needs an input shape of (1,28,28) **for each of the samples**.\n",
        "2. Convert the format of the input into `float32` (apparently the CNN works better with it).\n",
        "3. **Normalise** i.e. divide all values by 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQ-K3mWVceNW"
      },
      "outputs": [],
      "source": [
        "# 5. Preprocess input data\n",
        "# Reshape into four dimensions.\n",
        "X_train_reshape = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test_reshape = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "# Convert to float 32\n",
        "X_train_reshape = X_train_reshape.astype('float32')\n",
        "X_test_reshape = X_test_reshape.astype('float32')\n",
        "# normalise\n",
        "X_train_reshape /= 255 \n",
        "X_test_reshape /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKFFtX2uceNW"
      },
      "source": [
        "CNNs also like their target to be categorical, i.e. instead of the target being values from 0 to 9, each target value will be a vector indicating which is the class according to the position. Run the following cell to see what I mean..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADPnhYWsceNX"
      },
      "outputs": [],
      "source": [
        "# 6. Preprocess class labels\n",
        "Y_train_categorical = np_utils.to_categorical(Y_train, 10)\n",
        "Y_test_categorical = np_utils.to_categorical(Y_test, 10)\n",
        "# Show a sample target entry. You will see that this sample corresponds to a 5 as\n",
        "# there is a one in the 6th position (remember that python starts in 0)\n",
        "print(Y_train_categorical[0])\n",
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R68VWKQceNX"
      },
      "source": [
        "Now it's time to train the model. We will define a **sequential** CNN with two convolutional layers, a **max pooling** of size $2 \\times 2$ and a **dropout** of $0.25$. Then, we will add a **flatten** layer, add a **densely connected** layer with a **ReLu** activation, afterwards add another **dropout** of $0.5$, and finally add a densely connected layer to the output with a **softmax** activation function. This configuration is not strict and you can find many different examples, such as [this other one](https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d).\n",
        "**NOTE:** If you get an error, you may need to change the `input_shape` to (1,28,28), which means that you also need to change the shape of `X_train_reshape` and `X_test_reshape` to (X.shape[0],1,28,28)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx4knZzEceNY"
      },
      "outputs": [],
      "source": [
        "# 7. Define model architecture\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-cTJAdQceNY"
      },
      "source": [
        "After creating the model architecture, we will compile it. We will use the **adam** optimiser to improve the loss obtained by the **cross_entropy** method, and then we will request the model to obtain the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43j7UqN_ceNY"
      },
      "outputs": [],
      "source": [
        "# 8. Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yD3gLPUceNZ"
      },
      "source": [
        "Once compiled, we will fit this model using our training data. If your computer is slow, I recommend you **NOT** to use the entire training dataset. This can be done by reducing the number `n` to something smaller than 60'000. Also, you can reduce the number of **epochs**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9VwFe3zceNZ"
      },
      "outputs": [],
      "source": [
        "# 9. Fit model on training data\n",
        "n=100\n",
        "\n",
        "model.fit(X_train_reshape[:n], Y_train_categorical[:n], \n",
        "          batch_size=32, epochs=5, verbose=1) # verbose = 1 lets you see the training log for each iteration\n",
        "                                              # verbose = 2 would print only each 2 iterations!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVyGrc1CceNa"
      },
      "source": [
        "We can try to add more `n` and epochs to see how much `training accuracy` we are capable to achieve. Also, keep in mind that if the `loss` is not going down, then the model is not learning! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BhS9F1iceNa"
      },
      "source": [
        "Now we can evaluate your model in the `test` data. We can as well obtain the `loss`and the `accuracy` for this new, unseen data for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUiNBSzDceNa"
      },
      "outputs": [],
      "source": [
        "# 10. Evaluate model on test data\n",
        "loss, accuracy = model.evaluate(X_test_reshape[:n], Y_test_categorical[:n], verbose=0)\n",
        "print('Loss: ', loss,'\\nAcc: ', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP2Lz-ZwceNa"
      },
      "source": [
        "With the following cell you can print the labels that were predicted by the model. Notice that the classes are not categorical anymore!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Av_jSRtceNb"
      },
      "outputs": [],
      "source": [
        "# 11. Check the label that has been predicted\n",
        "predicted_labels = model.predict_classes(X_test_reshape[:n])\n",
        "print(predicted_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bxCWC1jceNb"
      },
      "source": [
        "The next cell has a brief code that will help you find the incorrect labels by comparing the labels obtained for the test samples with their ground truth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIGq2RWyceNb"
      },
      "outputs": [],
      "source": [
        "# 12. Check the label that has been predicted incorrectly\n",
        "incorrect_labels = np.nonzero(model.predict_classes(X_test_reshape[:n]).reshape((-1,))!= Y_test[:n])\n",
        "print(incorrect_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdVRNripceNc"
      },
      "source": [
        "Finally, you can use the following cell to print training or test cells from the dataset and see their actual (and predicted, for the case of test) labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBeZxo79ceNd"
      },
      "outputs": [],
      "source": [
        "# 13. Show a sample from the mnist dataset\n",
        "image_to_show = 72\n",
        "from_group = 'test' # put 'train' or 'test'\n",
        "if from_group == 'train':\n",
        "    plt.imshow(X_train[image_to_show])\n",
        "    print('Ground truth label: ',Y_train[image_to_show])\n",
        "else:\n",
        "    plt.imshow(X_test[image_to_show])\n",
        "    print('Ground truth label: ',Y_test[image_to_show])\n",
        "    if len(predicted_labels)>image_to_show:\n",
        "        print('Predicted label: ',predicted_labels[image_to_show])"
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "CMM536_T8_Lab.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}