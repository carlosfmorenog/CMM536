{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SSCxZ_rnDMU"
      },
      "source": [
        "# Topic 8 Lab Solved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAByEdJgnDMZ"
      },
      "source": [
        "Now that you know the basis of a CNN, you will run one of them in very few lines of code! To do so, we will use `Keras` with a `Tensorflow` backend, along with the very popular `mnist` dataset of handwritten numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfNlq1WknDMc"
      },
      "source": [
        "First, install the necessary packages if you don't have them already:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9grvxB__nDMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901ba7b5-ad36-40bd-9e5e-f9281ab9837c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.51.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "# 0. Installing the necesssary packages\n",
        "!pip install keras\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VUSmyOSnDMk"
      },
      "source": [
        "Then we will ensure that `Keras` uses `Tensorflow` as backend. Notice that if you prefer to use another backend such as `Theano`, you simply need to change the name in the second line of the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA00Jy9CnDMm"
      },
      "outputs": [],
      "source": [
        "# 1. Ensure you are using Theano backend\n",
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqaLJp47nDMn"
      },
      "source": [
        "Now you will import the necessary packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkZUAk8NnDMo"
      },
      "outputs": [],
      "source": [
        "# 2. Import libraries and modules\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOcoU4RynDMq"
      },
      "source": [
        "Then, we will set a **random seed** to be able to repeat the results and get the same results every time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0eUxbH6nDMr"
      },
      "outputs": [],
      "source": [
        "# 3. Set random seed (for reproducibility)\n",
        "np.random.seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-xSJAVJnDMs"
      },
      "source": [
        "With the following cell you will download the data from the `mnist` dataset. Notice that the data comes already partitioned in test and training sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04S0QwfnnDMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8f6fa6-6ef9-4ad9-8ee8-3506969d0129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# 4. Load pre-shuffled MNIST data into train and test sets\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9zkF8UMnDMu"
      },
      "source": [
        "Let's check the shape of the things obtained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDm-Hn2YnDMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccab0b07-f64b-4bcb-ec83-11ba451d4d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OCbcXrwnDMw"
      },
      "source": [
        "Notice that we have 60'000 samples for training and 10'000 for testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBkxkbCmnDMw"
      },
      "source": [
        "Now we will preprocess the data to be used by the classifier. To be able to use Keras, we need to do the following:\n",
        "1. **Reshape** the data into **four** dimensions i.e. the training set will be of shape (60000,28,28,1) and the test set of (10000,28,28). This is useful since the network needs an input shape of (1,28,28) **for each of the samples**.\n",
        "2. Convert the format of the input into `float32` (apparently the CNN works better with it).\n",
        "3. **Normalise** i.e. divide all values by 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj9YxpYfnDMx"
      },
      "outputs": [],
      "source": [
        "# 5. Preprocess input data\n",
        "# Reshape into four dimensions.\n",
        "X_train_reshape = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test_reshape = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "# Convert to float 32\n",
        "X_train_reshape = X_train_reshape.astype('float32')\n",
        "X_test_reshape = X_test_reshape.astype('float32')\n",
        "# normalise\n",
        "X_train_reshape /= 255 \n",
        "X_test_reshape /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSOyV4UbnDM0"
      },
      "source": [
        "CNNs also like their target to be categorical, i.e. instead of the target being values from 0 to 9, each target value will be a vector indicating which is the class according to the position. Run the following cell to see what I mean..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7QcNnlfnDM1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "84a17ca6-c656-43fd-aa44-02219d40fcdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f482287c2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# 6. Preprocess class labels\n",
        "Y_train_categorical = np_utils.to_categorical(Y_train, 10)\n",
        "Y_test_categorical = np_utils.to_categorical(Y_test, 10)\n",
        "# Show a sample target entry. You will see that this sample corresponds to a 5 as\n",
        "# there is a 1 in the 5th position (remember that python starts in 0)\n",
        "print(Y_train_categorical[0])\n",
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgx8rjqdnDM2"
      },
      "source": [
        "Now it's time to train the model. We will define a **sequential** CNN with two convolutional layers, a **max pooling** of size $2 \\times 2$ and a **dropout** of $0.25$. Then, we will add a **flatten** layer, add a **densely connected** layer with a **ReLu** activation, afterwards add another **dropout** of $0.5$, and finally add a densely connected layer to the output with a **softmax** activation function. This configuration is not strict and you can find many different examples, such as [this other one](https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYtZp2H6nDM3"
      },
      "outputs": [],
      "source": [
        "# 7. Define model architecture\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be congruent with what we saw on the lecture, let's see the model summary. Notice that before the dropout layer we had 589k features! But afterwards only 1290 are used."
      ],
      "metadata": {
        "id": "WcubYnCFSQS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Print a summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "CMn9aBgbSQpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b9989de-acf7-4ddc-8579-c52d065743b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               589952    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 600,810\n",
            "Trainable params: 600,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irGWXAn0nDM4"
      },
      "source": [
        "After creating the model architecture, we will compile it. We will use the **ADAM** optimiser to improve the loss obtained by the **categorical cross entropy** method, and then we will request the model to obtain the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPRq-xp8nDM5"
      },
      "outputs": [],
      "source": [
        "# 9. Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVlqDQ1PnDM5"
      },
      "source": [
        "Once compiled, we will fit this model using our training data. If your computer is slow, I recommend you **NOT** to use the entire training dataset. This can be done by reducing the number `n` to something smaller than 60'000. Also, you can reduce the number of **epochs**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta32g1OAnDM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fca2e1d0-8ba3-40c6-e0c5-4afd8bfc794c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "188/188 [==============================] - 23s 112ms/step - loss: 0.6550 - accuracy: 0.7900\n",
            "Epoch 2/5\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.2278 - accuracy: 0.9335\n",
            "Epoch 3/5\n",
            "188/188 [==============================] - 13s 71ms/step - loss: 0.1500 - accuracy: 0.9540\n",
            "Epoch 4/5\n",
            "188/188 [==============================] - 13s 68ms/step - loss: 0.1164 - accuracy: 0.9637\n",
            "Epoch 5/5\n",
            "188/188 [==============================] - 13s 70ms/step - loss: 0.0943 - accuracy: 0.9687\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f480c2c2310>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# 10. Fit model on training data\n",
        "n=6000 # In google colab, don't worry if you use all the data!\n",
        "\n",
        "model.fit(X_train_reshape[:n], Y_train_categorical[:n], \n",
        "          batch_size=32, epochs=5, verbose=1) # verbose = 1 lets you see the training log for each iteration, higher values just gives you a summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBBg9ykGnDM8"
      },
      "source": [
        "We can try to add more `n` and epochs to see how much `training accuracy` we are capable to achieve. Also, keep in mind that if the `loss` is not going down, then the model is not learning! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmtWTbg1nDM8"
      },
      "source": [
        "Now we can evaluate your model in the `test` data. We can as well obtain the `loss` and the `accuracy` for this new, unseen data for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEFP8jRfnDM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "342104be-9db6-476d-b039-ce8ff2f78194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  0.10629278421401978 \n",
            "Acc:  0.9643333554267883\n"
          ]
        }
      ],
      "source": [
        "# 11. Evaluate model on test data\n",
        "loss, accuracy = model.evaluate(X_test_reshape[:n], Y_test_categorical[:n], verbose=0)\n",
        "print('Loss: ', loss,'\\nAcc: ', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU40tKiqnDM9"
      },
      "source": [
        "With the following cell you can print the labels that were predicted by the model. Notice that the classes are not categorical anymore!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4ThHn12nDM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208a8fa1-57ba-40d2-cbad-42ea4c62d0bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 3s 15ms/step\n",
            "[7 2 1 ... 5 1 7]\n"
          ]
        }
      ],
      "source": [
        "# 12. Check the labels that have been predicted\n",
        "predict_x=model.predict(X_test[:n]) \n",
        "classes_x=np.argmax(predict_x,axis=1)\n",
        "print(classes_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkjLgh9ZnDM-"
      },
      "source": [
        "The next cell has a brief code that will help you find the incorrect labels by comparing the labels obtained for the test samples with their ground truth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-C-VpWPnDM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca4940f-75cd-484b-e0f8-45bb63146770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 73 was classified as 7 when it really was 9\n",
            "Sample 92 was classified as 4 when it really was 9\n",
            "Sample 125 was classified as 4 when it really was 9\n",
            "Sample 184 was classified as 2 when it really was 8\n",
            "Sample 247 was classified as 6 when it really was 4\n",
            "Sample 266 was classified as 0 when it really was 8\n",
            "Sample 290 was classified as 4 when it really was 8\n",
            "Sample 321 was classified as 7 when it really was 2\n",
            "Sample 340 was classified as 3 when it really was 5\n",
            "Sample 381 was classified as 7 when it really was 3\n",
            "Sample 445 was classified as 0 when it really was 6\n",
            "Sample 479 was classified as 8 when it really was 9\n",
            "Sample 495 was classified as 2 when it really was 8\n",
            "Sample 511 was classified as 1 when it really was 4\n",
            "Sample 530 was classified as 4 when it really was 9\n",
            "Sample 543 was classified as 7 when it really was 8\n",
            "Sample 578 was classified as 8 when it really was 3\n",
            "Sample 582 was classified as 2 when it really was 8\n",
            "Sample 591 was classified as 2 when it really was 8\n",
            "Sample 613 was classified as 8 when it really was 2\n",
            "Sample 659 was classified as 1 when it really was 2\n",
            "Sample 691 was classified as 4 when it really was 8\n",
            "Sample 717 was classified as 6 when it really was 0\n",
            "Sample 720 was classified as 8 when it really was 5\n",
            "Sample 740 was classified as 9 when it really was 4\n",
            "Sample 791 was classified as 9 when it really was 5\n",
            "Sample 839 was classified as 3 when it really was 8\n",
            "Sample 844 was classified as 7 when it really was 8\n",
            "Sample 924 was classified as 7 when it really was 2\n",
            "Sample 947 was classified as 9 when it really was 8\n",
            "Sample 950 was classified as 2 when it really was 7\n",
            "Sample 956 was classified as 2 when it really was 1\n",
            "Sample 965 was classified as 0 when it really was 6\n",
            "Sample 1014 was classified as 5 when it really was 6\n",
            "Sample 1032 was classified as 8 when it really was 5\n",
            "Sample 1039 was classified as 9 when it really was 7\n",
            "Sample 1068 was classified as 4 when it really was 8\n",
            "Sample 1114 was classified as 8 when it really was 3\n",
            "Sample 1119 was classified as 2 when it really was 7\n",
            "Sample 1166 was classified as 2 when it really was 3\n",
            "Sample 1181 was classified as 1 when it really was 6\n",
            "Sample 1182 was classified as 8 when it really was 6\n",
            "Sample 1204 was classified as 7 when it really was 3\n",
            "Sample 1206 was classified as 2 when it really was 7\n",
            "Sample 1224 was classified as 4 when it really was 2\n",
            "Sample 1226 was classified as 2 when it really was 7\n",
            "Sample 1232 was classified as 4 when it really was 9\n",
            "Sample 1247 was classified as 0 when it really was 9\n",
            "Sample 1260 was classified as 1 when it really was 7\n",
            "Sample 1283 was classified as 2 when it really was 7\n",
            "Sample 1290 was classified as 5 when it really was 3\n",
            "Sample 1299 was classified as 7 when it really was 5\n",
            "Sample 1319 was classified as 3 when it really was 8\n",
            "Sample 1325 was classified as 2 when it really was 8\n",
            "Sample 1326 was classified as 2 when it really was 7\n",
            "Sample 1337 was classified as 6 when it really was 2\n",
            "Sample 1364 was classified as 2 when it really was 8\n",
            "Sample 1393 was classified as 3 when it really was 5\n",
            "Sample 1429 was classified as 4 when it really was 9\n",
            "Sample 1500 was classified as 2 when it really was 7\n",
            "Sample 1522 was classified as 9 when it really was 7\n",
            "Sample 1527 was classified as 6 when it really was 1\n",
            "Sample 1530 was classified as 7 when it really was 8\n",
            "Sample 1549 was classified as 6 when it really was 4\n",
            "Sample 1621 was classified as 6 when it really was 0\n",
            "Sample 1681 was classified as 7 when it really was 3\n",
            "Sample 1694 was classified as 2 when it really was 8\n",
            "Sample 1709 was classified as 5 when it really was 9\n",
            "Sample 1717 was classified as 0 when it really was 8\n",
            "Sample 1721 was classified as 9 when it really was 7\n",
            "Sample 1737 was classified as 3 when it really was 5\n",
            "Sample 1754 was classified as 2 when it really was 7\n",
            "Sample 1790 was classified as 7 when it really was 2\n",
            "Sample 1850 was classified as 7 when it really was 8\n",
            "Sample 1878 was classified as 3 when it really was 8\n",
            "Sample 1901 was classified as 4 when it really was 9\n",
            "Sample 1913 was classified as 2 when it really was 3\n",
            "Sample 1955 was classified as 2 when it really was 8\n",
            "Sample 2016 was classified as 2 when it really was 7\n",
            "Sample 2043 was classified as 8 when it really was 4\n",
            "Sample 2044 was classified as 7 when it really was 2\n",
            "Sample 2049 was classified as 4 when it really was 9\n",
            "Sample 2052 was classified as 4 when it really was 8\n",
            "Sample 2098 was classified as 0 when it really was 2\n",
            "Sample 2109 was classified as 7 when it really was 3\n",
            "Sample 2118 was classified as 0 when it really was 6\n",
            "Sample 2125 was classified as 9 when it really was 5\n",
            "Sample 2129 was classified as 2 when it really was 9\n",
            "Sample 2130 was classified as 9 when it really was 4\n",
            "Sample 2135 was classified as 1 when it really was 6\n",
            "Sample 2168 was classified as 2 when it really was 8\n",
            "Sample 2182 was classified as 2 when it really was 1\n",
            "Sample 2185 was classified as 8 when it really was 0\n",
            "Sample 2189 was classified as 1 when it really was 9\n",
            "Sample 2224 was classified as 6 when it really was 5\n",
            "Sample 2237 was classified as 6 when it really was 5\n",
            "Sample 2266 was classified as 6 when it really was 1\n",
            "Sample 2280 was classified as 5 when it really was 3\n",
            "Sample 2293 was classified as 0 when it really was 9\n",
            "Sample 2298 was classified as 3 when it really was 8\n",
            "Sample 2299 was classified as 8 when it really was 2\n",
            "Sample 2369 was classified as 6 when it really was 5\n",
            "Sample 2382 was classified as 2 when it really was 8\n",
            "Sample 2387 was classified as 1 when it really was 9\n",
            "Sample 2395 was classified as 2 when it really was 8\n",
            "Sample 2406 was classified as 1 when it really was 9\n",
            "Sample 2408 was classified as 5 when it really was 3\n",
            "Sample 2414 was classified as 4 when it really was 9\n",
            "Sample 2422 was classified as 4 when it really was 6\n",
            "Sample 2425 was classified as 7 when it really was 8\n",
            "Sample 2454 was classified as 8 when it really was 6\n",
            "Sample 2488 was classified as 4 when it really was 2\n",
            "Sample 2560 was classified as 2 when it really was 3\n",
            "Sample 2573 was classified as 8 when it really was 5\n",
            "Sample 2607 was classified as 2 when it really was 7\n",
            "Sample 2654 was classified as 1 when it really was 6\n",
            "Sample 2730 was classified as 4 when it really was 7\n",
            "Sample 2758 was classified as 5 when it really was 8\n",
            "Sample 2760 was classified as 4 when it really was 9\n",
            "Sample 2780 was classified as 3 when it really was 2\n",
            "Sample 2812 was classified as 4 when it really was 9\n",
            "Sample 2896 was classified as 0 when it really was 8\n",
            "Sample 2921 was classified as 2 when it really was 3\n",
            "Sample 2925 was classified as 7 when it really was 5\n",
            "Sample 2927 was classified as 2 when it really was 3\n",
            "Sample 2953 was classified as 5 when it really was 3\n",
            "Sample 2995 was classified as 8 when it really was 6\n",
            "Sample 3012 was classified as 4 when it really was 8\n",
            "Sample 3060 was classified as 7 when it really was 9\n",
            "Sample 3073 was classified as 2 when it really was 1\n",
            "Sample 3206 was classified as 3 when it really was 8\n",
            "Sample 3289 was classified as 9 when it really was 8\n",
            "Sample 3316 was classified as 4 when it really was 7\n",
            "Sample 3329 was classified as 2 when it really was 7\n",
            "Sample 3333 was classified as 9 when it really was 7\n",
            "Sample 3336 was classified as 9 when it really was 5\n",
            "Sample 3376 was classified as 9 when it really was 7\n",
            "Sample 3422 was classified as 0 when it really was 6\n",
            "Sample 3475 was classified as 7 when it really was 3\n",
            "Sample 3503 was classified as 1 when it really was 9\n",
            "Sample 3520 was classified as 4 when it really was 6\n",
            "Sample 3549 was classified as 2 when it really was 3\n",
            "Sample 3558 was classified as 0 when it really was 5\n",
            "Sample 3565 was classified as 8 when it really was 5\n",
            "Sample 3597 was classified as 2 when it really was 9\n",
            "Sample 3599 was classified as 7 when it really was 2\n",
            "Sample 3629 was classified as 3 when it really was 8\n",
            "Sample 3662 was classified as 0 when it really was 8\n",
            "Sample 3664 was classified as 4 when it really was 9\n",
            "Sample 3726 was classified as 9 when it really was 4\n",
            "Sample 3727 was classified as 3 when it really was 8\n",
            "Sample 3757 was classified as 2 when it really was 8\n",
            "Sample 3767 was classified as 2 when it really was 7\n",
            "Sample 3776 was classified as 8 when it really was 5\n",
            "Sample 3778 was classified as 8 when it really was 5\n",
            "Sample 3780 was classified as 6 when it really was 4\n",
            "Sample 3782 was classified as 2 when it really was 8\n",
            "Sample 3796 was classified as 8 when it really was 2\n",
            "Sample 3801 was classified as 0 when it really was 6\n",
            "Sample 3806 was classified as 8 when it really was 5\n",
            "Sample 3808 was classified as 8 when it really was 7\n",
            "Sample 3818 was classified as 6 when it really was 0\n",
            "Sample 3848 was classified as 2 when it really was 7\n",
            "Sample 3850 was classified as 4 when it really was 9\n",
            "Sample 3853 was classified as 0 when it really was 6\n",
            "Sample 3855 was classified as 0 when it really was 5\n",
            "Sample 3869 was classified as 4 when it really was 9\n",
            "Sample 3893 was classified as 6 when it really was 5\n",
            "Sample 3906 was classified as 2 when it really was 1\n",
            "Sample 3941 was classified as 6 when it really was 4\n",
            "Sample 3968 was classified as 8 when it really was 5\n",
            "Sample 4007 was classified as 9 when it really was 7\n",
            "Sample 4075 was classified as 0 when it really was 8\n",
            "Sample 4078 was classified as 2 when it really was 9\n",
            "Sample 4093 was classified as 4 when it really was 9\n",
            "Sample 4163 was classified as 0 when it really was 9\n",
            "Sample 4176 was classified as 7 when it really was 2\n",
            "Sample 4199 was classified as 9 when it really was 7\n",
            "Sample 4205 was classified as 1 when it really was 2\n",
            "Sample 4224 was classified as 7 when it really was 9\n",
            "Sample 4248 was classified as 1 when it really was 2\n",
            "Sample 4256 was classified as 2 when it really was 3\n",
            "Sample 4289 was classified as 7 when it really was 2\n",
            "Sample 4294 was classified as 7 when it really was 9\n",
            "Sample 4306 was classified as 7 when it really was 3\n",
            "Sample 4360 was classified as 3 when it really was 5\n",
            "Sample 4369 was classified as 4 when it really was 9\n",
            "Sample 4425 was classified as 4 when it really was 9\n",
            "Sample 4433 was classified as 2 when it really was 7\n",
            "Sample 4435 was classified as 7 when it really was 3\n",
            "Sample 4443 was classified as 2 when it really was 3\n",
            "Sample 4454 was classified as 7 when it really was 9\n",
            "Sample 4500 was classified as 1 when it really was 9\n",
            "Sample 4548 was classified as 8 when it really was 5\n",
            "Sample 4575 was classified as 2 when it really was 4\n",
            "Sample 4601 was classified as 7 when it really was 8\n",
            "Sample 4615 was classified as 4 when it really was 2\n",
            "Sample 4639 was classified as 9 when it really was 8\n",
            "Sample 4690 was classified as 2 when it really was 7\n",
            "Sample 4724 was classified as 2 when it really was 8\n",
            "Sample 4731 was classified as 7 when it really was 8\n",
            "Sample 4740 was classified as 5 when it really was 3\n",
            "Sample 4761 was classified as 8 when it really was 9\n",
            "Sample 4785 was classified as 8 when it really was 3\n",
            "Sample 4807 was classified as 0 when it really was 8\n",
            "Sample 4808 was classified as 5 when it really was 3\n",
            "Sample 4814 was classified as 4 when it really was 6\n",
            "Sample 4823 was classified as 4 when it really was 9\n",
            "Sample 4837 was classified as 2 when it really was 7\n",
            "Sample 4839 was classified as 2 when it really was 8\n",
            "Sample 4876 was classified as 4 when it really was 2\n",
            "Sample 4886 was classified as 2 when it really was 7\n",
            "Sample 4890 was classified as 6 when it really was 8\n",
            "Sample 4918 was classified as 4 when it really was 9\n",
            "Sample 4956 was classified as 4 when it really was 8\n",
            "Sample 5067 was classified as 2 when it really was 3\n",
            "Sample 5140 was classified as 5 when it really was 3\n",
            "Sample 5288 was classified as 9 when it really was 8\n",
            "Sample 5331 was classified as 6 when it really was 1\n",
            "Sample 5600 was classified as 9 when it really was 7\n",
            "Sample 5611 was classified as 1 when it really was 8\n",
            "Sample 5613 was classified as 6 when it really was 0\n",
            "Sample 5642 was classified as 8 when it really was 1\n",
            "Sample 5709 was classified as 9 when it really was 7\n",
            "Sample 5734 was classified as 7 when it really was 3\n",
            "Sample 5801 was classified as 0 when it really was 6\n",
            "Sample 5887 was classified as 9 when it really was 7\n",
            "Sample 5888 was classified as 0 when it really was 4\n",
            "Sample 5937 was classified as 3 when it really was 5\n",
            "Sample 5955 was classified as 8 when it really was 3\n",
            "Sample 5973 was classified as 8 when it really was 3\n"
          ]
        }
      ],
      "source": [
        "# 13. Check the label that has been predicted incorrectly\n",
        "incorrect_labels=[]\n",
        "accuracy = 0\n",
        "for i,cla in enumerate(classes_x):\n",
        "  if cla != Y_test[:n][i]:\n",
        "    print(\"Sample \"+str(i)+\" was classified as \"+str(cla)+\" when it really was \"+str(Y_test[:n][i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1oAQn11nDNA"
      },
      "source": [
        "Finally, you can use the following cell to print training or test cells from the dataset and see their actual (and predicted, for the case of test) labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78oido3SnDNA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "f840ff3d-686a-4a92-c4ca-5ac97de63fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground truth label:  2\n",
            "Predicted label:  2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# 14. Show a sample from the mnist dataset\n",
        "image_to_show = 72\n",
        "from_group = 'test' # 'train' or 'test'\n",
        "if from_group == 'train':\n",
        "    plt.imshow(X_train[image_to_show])\n",
        "    print('Ground truth label: ',Y_train[image_to_show])\n",
        "else:\n",
        "    plt.imshow(X_test[image_to_show])\n",
        "    print('Ground truth label: ',Y_test[image_to_show])\n",
        "    if len(predict_x)>image_to_show:\n",
        "        print('Predicted label: ',classes_x[image_to_show])"
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}