{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosfmorenog/CMM536/blob/master/CMM536_Topic_8/CMM536_T8_Lab_Solved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SSCxZ_rnDMU"
      },
      "source": [
        "# Topic 8 Lab Solved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAByEdJgnDMZ"
      },
      "source": [
        "Now that you know the basis of a CNN, you will run one of them in very few lines of code! To do so, we will use `Keras` with a `Tensorflow` backend, along with the very popular `mnist` dataset of handwritten numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfNlq1WknDMc"
      },
      "source": [
        "First, install the necessary packages if you don't have them already:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9grvxB__nDMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664efdba-4760-4985-ade8-882182cd88a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "# 0. Installing the necesssary packages\n",
        "!pip install keras\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VUSmyOSnDMk"
      },
      "source": [
        "Then we will ensure that `Keras` uses `Tensorflow` as backend. Notice that if you prefer to use another backend such as `Theano`, you simply need to change the name in the second line of the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dA00Jy9CnDMm"
      },
      "outputs": [],
      "source": [
        "# 1. Ensure you are using Theano backend\n",
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqaLJp47nDMn"
      },
      "source": [
        "Now you will import the necessary packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nkZUAk8NnDMo"
      },
      "outputs": [],
      "source": [
        "# 2. Import libraries and modules\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras import utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOcoU4RynDMq"
      },
      "source": [
        "Then, we will set a **random seed** to be able to repeat the results and get the same results every time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i0eUxbH6nDMr"
      },
      "outputs": [],
      "source": [
        "# 3. Set random seed (for reproducibility)\n",
        "np.random.seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-xSJAVJnDMs"
      },
      "source": [
        "With the following cell you will download the data from the `mnist` dataset. Notice that the data comes already partitioned in test and training sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "04S0QwfnnDMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9c27b5-b9ca-447c-9487-6aa36cbdacb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# 4. Load pre-shuffled MNIST data into train and test sets\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9zkF8UMnDMu"
      },
      "source": [
        "Let's check the shape of the things obtained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CDm-Hn2YnDMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c19120d-fbea-4d6c-b37a-16cfb1993817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OCbcXrwnDMw"
      },
      "source": [
        "Notice that we have 60'000 samples for training and 10'000 for testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBkxkbCmnDMw"
      },
      "source": [
        "Now we will preprocess the data to be used by the classifier. To be able to use Keras, we need to do the following:\n",
        "1. **Reshape** the data into **four** dimensions i.e. the training set will be of shape (60000,28,28,1) and the test set of (10000,28,28). This is useful since the network needs an input shape of (1,28,28) **for each of the samples**.\n",
        "2. Convert the format of the input into `float32` (apparently the CNN works better with it).\n",
        "3. **Normalise** i.e. divide all values by 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tj9YxpYfnDMx"
      },
      "outputs": [],
      "source": [
        "# 5. Preprocess input data\n",
        "# Reshape into four dimensions.\n",
        "X_train_reshape = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test_reshape = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "# Convert to float 32\n",
        "X_train_reshape = X_train_reshape.astype('float32')\n",
        "X_test_reshape = X_test_reshape.astype('float32')\n",
        "# normalise\n",
        "X_train_reshape /= 255\n",
        "X_test_reshape /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSOyV4UbnDM0"
      },
      "source": [
        "CNNs also like their target to be categorical, i.e. instead of the target being values from 0 to 9, each target value will be a vector indicating which is the class according to the position. Run the following cell to see what I mean..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "v7QcNnlfnDM1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "d17531ff-e383-463d-8239-f26579150fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c6d184fee00>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 6. Preprocess class labels\n",
        "Y_train_categorical = utils.to_categorical(Y_train, 10)\n",
        "Y_test_categorical = utils.to_categorical(Y_test, 10)\n",
        "# Show a sample target entry. You will see that this sample corresponds to a 5 as\n",
        "# there is a 1 in the 5th position (remember that python starts in 0)\n",
        "print(Y_train_categorical[0])\n",
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgx8rjqdnDM2"
      },
      "source": [
        "Now it's time to train the model. We will define a **sequential** CNN with two convolutional layers, a **max pooling** of size $2 \\times 2$ and a **dropout** of $0.25$. Then, we will add a **flatten** layer, add a **densely connected** layer with a **ReLu** activation, afterwards add another **dropout** of $0.5$, and finally add a densely connected layer to the output with a **softmax** activation function. This configuration is not strict and you can find many different examples, such as [this other one](https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tYtZp2H6nDM3"
      },
      "outputs": [],
      "source": [
        "# 7. Define model architecture\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be congruent with what we saw on the lecture, let's see the model summary. Notice that before the dropout layer we had 589k features! But afterwards only 1290 are used."
      ],
      "metadata": {
        "id": "WcubYnCFSQS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Print a summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "CMn9aBgbSQpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69505f6c-3f6e-43be-bf9f-7383c8f43e95"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 12, 12, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               589952    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 600810 (2.29 MB)\n",
            "Trainable params: 600810 (2.29 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irGWXAn0nDM4"
      },
      "source": [
        "After creating the model architecture, we will compile it. We will use the **ADAM** optimiser to improve the loss obtained by the **categorical cross entropy** method, and then we will request the model to obtain the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rPRq-xp8nDM5"
      },
      "outputs": [],
      "source": [
        "# 9. Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVlqDQ1PnDM5"
      },
      "source": [
        "Once compiled, we will fit this model using our training data. If your computer is slow, I recommend you **NOT** to use the entire training dataset. This can be done by reducing the number `n` to something smaller than 60'000. Also, you can reduce the number of **epochs**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ta32g1OAnDM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a836e2a-2cd3-4ef2-a1e1-8c1ab8c3de72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "188/188 [==============================] - 20s 103ms/step - loss: 0.6664 - accuracy: 0.7938\n",
            "Epoch 2/5\n",
            "188/188 [==============================] - 21s 113ms/step - loss: 0.2268 - accuracy: 0.9338\n",
            "Epoch 3/5\n",
            "188/188 [==============================] - 10s 53ms/step - loss: 0.1577 - accuracy: 0.9533\n",
            "Epoch 4/5\n",
            "188/188 [==============================] - 10s 55ms/step - loss: 0.1203 - accuracy: 0.9615\n",
            "Epoch 5/5\n",
            "188/188 [==============================] - 9s 48ms/step - loss: 0.1028 - accuracy: 0.9710\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c6d044998a0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# 10. Fit model on training data\n",
        "n=6000 # In google colab, don't worry if you use all the data!\n",
        "\n",
        "model.fit(X_train_reshape[:n], Y_train_categorical[:n],\n",
        "          batch_size=32, epochs=5, verbose=1) # verbose = 1 lets you see the training log for each iteration, higher values just gives you a summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBBg9ykGnDM8"
      },
      "source": [
        "We can try to add more `n` and epochs to see how much `training accuracy` we are capable to achieve. Also, keep in mind that if the `loss` is not going down, then the model is not learning!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmtWTbg1nDM8"
      },
      "source": [
        "Now we can evaluate your model in the `test` data. We can as well obtain the `loss` and the `accuracy` for this new, unseen data for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qEFP8jRfnDM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7245754f-c9e1-40ce-dbd0-6d0ed63099c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  0.11016453802585602 \n",
            "Acc:  0.9651666879653931\n"
          ]
        }
      ],
      "source": [
        "# 11. Evaluate model on test data\n",
        "loss, accuracy = model.evaluate(X_test_reshape[:n], Y_test_categorical[:n], verbose=0)\n",
        "print('Loss: ', loss,'\\nAcc: ', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU40tKiqnDM9"
      },
      "source": [
        "With the following cell you can print the labels that were predicted by the model. Notice that the classes are not categorical anymore!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Z4ThHn12nDM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6457dca-61b7-4979-ef7f-5d35b98dcde9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 3s 13ms/step\n",
            "[7 2 1 ... 3 1 7]\n"
          ]
        }
      ],
      "source": [
        "# 12. Check the labels that have been predicted\n",
        "m=6000\n",
        "\n",
        "predict_x=model.predict(X_test[:m])\n",
        "classes_x=np.argmax(predict_x,axis=1)\n",
        "print(classes_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkjLgh9ZnDM-"
      },
      "source": [
        "The next cell has a brief code that will help you find the incorrect labels by comparing the labels obtained for the test samples with their ground truth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "f-C-VpWPnDM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17d3ba81-8d8c-4dbf-dff5-50eca452e860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 264 was classified as 4 when it really was 9\n",
            "Sample 266 was classified as 0 when it really was 8\n",
            "Sample 290 was classified as 4 when it really was 8\n",
            "Sample 320 was classified as 7 when it really was 9\n",
            "Sample 321 was classified as 7 when it really was 2\n",
            "Sample 445 was classified as 0 when it really was 6\n",
            "Sample 543 was classified as 3 when it really was 8\n",
            "Sample 571 was classified as 9 when it really was 4\n",
            "Sample 582 was classified as 2 when it really was 8\n",
            "Sample 591 was classified as 3 when it really was 8\n",
            "Sample 646 was classified as 6 when it really was 2\n",
            "Sample 659 was classified as 7 when it really was 2\n",
            "Sample 684 was classified as 3 when it really was 7\n",
            "Sample 691 was classified as 4 when it really was 8\n",
            "Sample 717 was classified as 6 when it really was 0\n",
            "Sample 720 was classified as 6 when it really was 5\n",
            "Sample 740 was classified as 9 when it really was 4\n",
            "Sample 839 was classified as 3 when it really was 8\n",
            "Sample 844 was classified as 7 when it really was 8\n",
            "Sample 924 was classified as 7 when it really was 2\n",
            "Sample 938 was classified as 5 when it really was 3\n",
            "Sample 939 was classified as 0 when it really was 2\n",
            "Sample 947 was classified as 9 when it really was 8\n",
            "Sample 956 was classified as 6 when it really was 1\n",
            "Sample 965 was classified as 0 when it really was 6\n",
            "Sample 1014 was classified as 5 when it really was 6\n",
            "Sample 1039 was classified as 9 when it really was 7\n",
            "Sample 1068 was classified as 4 when it really was 8\n",
            "Sample 1107 was classified as 3 when it really was 9\n",
            "Sample 1112 was classified as 6 when it really was 4\n",
            "Sample 1119 was classified as 2 when it really was 7\n",
            "Sample 1181 was classified as 1 when it really was 6\n",
            "Sample 1192 was classified as 4 when it really was 9\n",
            "Sample 1224 was classified as 6 when it really was 2\n",
            "Sample 1226 was classified as 2 when it really was 7\n",
            "Sample 1232 was classified as 4 when it really was 9\n",
            "Sample 1247 was classified as 0 when it really was 9\n",
            "Sample 1260 was classified as 1 when it really was 7\n",
            "Sample 1290 was classified as 5 when it really was 3\n",
            "Sample 1299 was classified as 7 when it really was 5\n",
            "Sample 1319 was classified as 7 when it really was 8\n",
            "Sample 1325 was classified as 6 when it really was 8\n",
            "Sample 1326 was classified as 2 when it really was 7\n",
            "Sample 1337 was classified as 6 when it really was 2\n",
            "Sample 1393 was classified as 3 when it really was 5\n",
            "Sample 1425 was classified as 6 when it really was 8\n",
            "Sample 1429 was classified as 4 when it really was 9\n",
            "Sample 1527 was classified as 6 when it really was 1\n",
            "Sample 1530 was classified as 7 when it really was 8\n",
            "Sample 1549 was classified as 6 when it really was 4\n",
            "Sample 1553 was classified as 3 when it really was 9\n",
            "Sample 1554 was classified as 8 when it really was 9\n",
            "Sample 1611 was classified as 5 when it really was 3\n",
            "Sample 1621 was classified as 6 when it really was 0\n",
            "Sample 1681 was classified as 7 when it really was 3\n",
            "Sample 1686 was classified as 6 when it really was 8\n",
            "Sample 1709 was classified as 5 when it really was 9\n",
            "Sample 1717 was classified as 0 when it really was 8\n",
            "Sample 1737 was classified as 2 when it really was 5\n",
            "Sample 1754 was classified as 2 when it really was 7\n",
            "Sample 1790 was classified as 7 when it really was 2\n",
            "Sample 1850 was classified as 7 when it really was 8\n",
            "Sample 1878 was classified as 3 when it really was 8\n",
            "Sample 1901 was classified as 4 when it really was 9\n",
            "Sample 1955 was classified as 2 when it really was 8\n",
            "Sample 1968 was classified as 1 when it really was 8\n",
            "Sample 2016 was classified as 2 when it really was 7\n",
            "Sample 2035 was classified as 3 when it really was 5\n",
            "Sample 2040 was classified as 6 when it really was 5\n",
            "Sample 2043 was classified as 8 when it really was 4\n",
            "Sample 2044 was classified as 7 when it really was 2\n",
            "Sample 2052 was classified as 4 when it really was 8\n",
            "Sample 2053 was classified as 9 when it really was 4\n",
            "Sample 2098 was classified as 0 when it really was 2\n",
            "Sample 2107 was classified as 0 when it really was 8\n",
            "Sample 2109 was classified as 7 when it really was 3\n",
            "Sample 2118 was classified as 0 when it really was 6\n",
            "Sample 2129 was classified as 8 when it really was 9\n",
            "Sample 2130 was classified as 9 when it really was 4\n",
            "Sample 2135 was classified as 1 when it really was 6\n",
            "Sample 2168 was classified as 2 when it really was 8\n",
            "Sample 2182 was classified as 3 when it really was 1\n",
            "Sample 2186 was classified as 8 when it really was 2\n",
            "Sample 2189 was classified as 1 when it really was 9\n",
            "Sample 2224 was classified as 6 when it really was 5\n",
            "Sample 2266 was classified as 6 when it really was 1\n",
            "Sample 2272 was classified as 0 when it really was 8\n",
            "Sample 2280 was classified as 5 when it really was 3\n",
            "Sample 2293 was classified as 0 when it really was 9\n",
            "Sample 2325 was classified as 3 when it really was 7\n",
            "Sample 2369 was classified as 6 when it really was 5\n",
            "Sample 2387 was classified as 1 when it really was 9\n",
            "Sample 2406 was classified as 1 when it really was 9\n",
            "Sample 2414 was classified as 4 when it really was 9\n",
            "Sample 2422 was classified as 4 when it really was 6\n",
            "Sample 2425 was classified as 7 when it really was 8\n",
            "Sample 2447 was classified as 9 when it really was 4\n",
            "Sample 2462 was classified as 0 when it really was 2\n",
            "Sample 2488 was classified as 4 when it really was 2\n",
            "Sample 2597 was classified as 3 when it really was 5\n",
            "Sample 2607 was classified as 8 when it really was 7\n",
            "Sample 2654 was classified as 1 when it really was 6\n",
            "Sample 2758 was classified as 5 when it really was 8\n",
            "Sample 2780 was classified as 3 when it really was 2\n",
            "Sample 2812 was classified as 4 when it really was 9\n",
            "Sample 2894 was classified as 6 when it really was 0\n",
            "Sample 2896 was classified as 0 when it really was 8\n",
            "Sample 2925 was classified as 0 when it really was 5\n",
            "Sample 2930 was classified as 7 when it really was 5\n",
            "Sample 2939 was classified as 7 when it really was 9\n",
            "Sample 2970 was classified as 3 when it really was 5\n",
            "Sample 2995 was classified as 8 when it really was 6\n",
            "Sample 3060 was classified as 7 when it really was 9\n",
            "Sample 3073 was classified as 2 when it really was 1\n",
            "Sample 3114 was classified as 6 when it really was 4\n",
            "Sample 3117 was classified as 9 when it really was 5\n",
            "Sample 3206 was classified as 3 when it really was 8\n",
            "Sample 3336 was classified as 7 when it really was 5\n",
            "Sample 3384 was classified as 6 when it really was 2\n",
            "Sample 3503 was classified as 1 when it really was 9\n",
            "Sample 3520 was classified as 4 when it really was 6\n",
            "Sample 3558 was classified as 0 when it really was 5\n",
            "Sample 3597 was classified as 3 when it really was 9\n",
            "Sample 3629 was classified as 3 when it really was 8\n",
            "Sample 3662 was classified as 0 when it really was 8\n",
            "Sample 3726 was classified as 9 when it really was 4\n",
            "Sample 3751 was classified as 2 when it really was 7\n",
            "Sample 3767 was classified as 2 when it really was 7\n",
            "Sample 3780 was classified as 6 when it really was 4\n",
            "Sample 3794 was classified as 3 when it really was 8\n",
            "Sample 3801 was classified as 0 when it really was 6\n",
            "Sample 3806 was classified as 8 when it really was 5\n",
            "Sample 3808 was classified as 8 when it really was 7\n",
            "Sample 3811 was classified as 3 when it really was 2\n",
            "Sample 3818 was classified as 6 when it really was 0\n",
            "Sample 3853 was classified as 0 when it really was 6\n",
            "Sample 3855 was classified as 0 when it really was 5\n",
            "Sample 3893 was classified as 6 when it really was 5\n",
            "Sample 3906 was classified as 2 when it really was 1\n",
            "Sample 3926 was classified as 3 when it really was 9\n",
            "Sample 3941 was classified as 6 when it really was 4\n",
            "Sample 3951 was classified as 9 when it really was 8\n",
            "Sample 3985 was classified as 4 when it really was 9\n",
            "Sample 4007 was classified as 9 when it really was 7\n",
            "Sample 4075 was classified as 6 when it really was 8\n",
            "Sample 4078 was classified as 3 when it really was 9\n",
            "Sample 4116 was classified as 6 when it really was 8\n",
            "Sample 4152 was classified as 1 when it really was 5\n",
            "Sample 4163 was classified as 0 when it really was 9\n",
            "Sample 4176 was classified as 7 when it really was 2\n",
            "Sample 4205 was classified as 1 when it really was 2\n",
            "Sample 4212 was classified as 2 when it really was 1\n",
            "Sample 4224 was classified as 7 when it really was 9\n",
            "Sample 4238 was classified as 3 when it really was 7\n",
            "Sample 4248 was classified as 1 when it really was 2\n",
            "Sample 4256 was classified as 2 when it really was 3\n",
            "Sample 4289 was classified as 7 when it really was 2\n",
            "Sample 4294 was classified as 7 when it really was 9\n",
            "Sample 4306 was classified as 7 when it really was 3\n",
            "Sample 4360 was classified as 3 when it really was 5\n",
            "Sample 4399 was classified as 0 when it really was 8\n",
            "Sample 4425 was classified as 4 when it really was 9\n",
            "Sample 4433 was classified as 2 when it really was 7\n",
            "Sample 4497 was classified as 7 when it really was 8\n",
            "Sample 4500 was classified as 1 when it really was 9\n",
            "Sample 4548 was classified as 6 when it really was 5\n",
            "Sample 4575 was classified as 2 when it really was 4\n",
            "Sample 4601 was classified as 4 when it really was 8\n",
            "Sample 4615 was classified as 4 when it really was 2\n",
            "Sample 4639 was classified as 9 when it really was 8\n",
            "Sample 4731 was classified as 7 when it really was 8\n",
            "Sample 4740 was classified as 5 when it really was 3\n",
            "Sample 4743 was classified as 6 when it really was 8\n",
            "Sample 4751 was classified as 6 when it really was 4\n",
            "Sample 4761 was classified as 8 when it really was 9\n",
            "Sample 4807 was classified as 0 when it really was 8\n",
            "Sample 4808 was classified as 5 when it really was 3\n",
            "Sample 4814 was classified as 0 when it really was 6\n",
            "Sample 4823 was classified as 4 when it really was 9\n",
            "Sample 4860 was classified as 9 when it really was 4\n",
            "Sample 4874 was classified as 0 when it really was 9\n",
            "Sample 4876 was classified as 4 when it really was 2\n",
            "Sample 4890 was classified as 6 when it really was 8\n",
            "Sample 4950 was classified as 3 when it really was 2\n",
            "Sample 4956 was classified as 4 when it really was 8\n",
            "Sample 4978 was classified as 7 when it really was 8\n",
            "Sample 5067 was classified as 2 when it really was 3\n",
            "Sample 5140 was classified as 5 when it really was 3\n",
            "Sample 5159 was classified as 9 when it really was 4\n",
            "Sample 5278 was classified as 9 when it really was 8\n",
            "Sample 5288 was classified as 0 when it really was 8\n",
            "Sample 5331 was classified as 6 when it really was 1\n",
            "Sample 5634 was classified as 3 when it really was 2\n",
            "Sample 5642 was classified as 8 when it really was 1\n",
            "Sample 5734 was classified as 7 when it really was 3\n",
            "Sample 5887 was classified as 0 when it really was 7\n",
            "Sample 5888 was classified as 0 when it really was 4\n",
            "Sample 5937 was classified as 3 when it really was 5\n",
            "Sample 5955 was classified as 8 when it really was 3\n",
            "Sample 5997 was classified as 3 when it really was 5\n"
          ]
        }
      ],
      "source": [
        "# 13. Check the label that has been predicted incorrectly\n",
        "incorrect_labels=[]\n",
        "accuracy = 0\n",
        "for i,cla in enumerate(classes_x):\n",
        "  if cla != Y_test[:n][i]:\n",
        "    print(\"Sample \"+str(i)+\" was classified as \"+str(cla)+\" when it really was \"+str(Y_test[:n][i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1oAQn11nDNA"
      },
      "source": [
        "Finally, you can use the following cell to print training or test cells from the dataset and see their actual (and predicted, for the case of test) labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "78oido3SnDNA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "c0f7644f-5104-450f-c75c-250a90d40b92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground truth label:  2\n",
            "Predicted label:  2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 14. Show a sample from the mnist dataset (correct prediction)\n",
        "image_to_show = 72\n",
        "from_group = 'test' # 'train' or 'test'\n",
        "if from_group == 'train':\n",
        "    plt.imshow(X_train[image_to_show])\n",
        "    print('Ground truth label: ',Y_train[image_to_show])\n",
        "else:\n",
        "    plt.imshow(X_test[image_to_show])\n",
        "    print('Ground truth label: ',Y_test[image_to_show])\n",
        "    if len(predict_x)>image_to_show:\n",
        "        print('Predicted label: ',classes_x[image_to_show])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "cb04259c-780d-4664-8d00-c3d890283159",
        "id": "A46WHm0Sampl"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground truth label:  9\n",
            "Predicted label:  4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbUUlEQVR4nO3df3DU9b3v8dfyIytqsjGEZJMSaEAFK5COFNJURSwZkngOA8g4gLYDjgMXGrxF/DXpqAjtmbR4xjpyEGbOUagzgj/OCBw9lnswmDC2Cb1EuAxjzSXcKLGQoEzZDUFCIJ/7B8etC4n0u+zmnQ3Px8x3hux+P/m+/Xb12S+7+cbnnHMCAKCXDbAeAABwdSJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAxCDrAS7W1dWlo0ePKjU1VT6fz3ocAIBHzjm1tbUpNzdXAwb0fJ3T5wJ09OhR5eXlWY8BALhCzc3NGj58eI/P97kApaamSpLu0D0apMHG0wAAvDqnTn2o9yL/Pe9JwgK0bt06Pffcc2ppaVFBQYHWrl2ryZMnX3bd13/tNkiDNchHgAAg6fz3HUYv9zZKQj6E8MYbb2jFihVauXKlPvroIxUUFKikpETHjx9PxOEAAEkoIQF6/vnntWjRIj344IP63ve+pw0bNujaa6/VK6+8kojDAQCSUNwDdPbsWdXX16u4uPhvBxkwQMXFxaqtrb1k/46ODoXD4agNAND/xT1AX375pc6fP6/s7Oyox7Ozs9XS0nLJ/pWVlQoEApGNT8ABwNXB/AdRKyoqFAqFIltzc7P1SACAXhD3T8FlZmZq4MCBam1tjXq8tbVVwWDwkv39fr/8fn+8xwAA9HFxvwJKSUnRxIkTVVVVFXmsq6tLVVVVKioqivfhAABJKiE/B7RixQotWLBAP/jBDzR58mS98MILam9v14MPPpiIwwEAklBCAjR37lx98cUXeuaZZ9TS0qLvf//72rFjxyUfTAAAXL18zjlnPcQ3hcNhBQIBTdVM7oQAAEnonOtUtbYrFAopLS2tx/3MPwUHALg6ESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYGWQ8AJMKhtYUxrdv8Dy95XnO4M8vzmld+NsvzmkFV9Z7XAH0ZV0AAABMECABgIu4BevbZZ+Xz+aK2sWPHxvswAIAkl5D3gG699Va9//77fzvIIN5qAgBES0gZBg0apGAwmIhvDQDoJxLyHtChQ4eUm5urUaNG6YEHHtCRI0d63Lejo0PhcDhqAwD0f3EPUGFhoTZt2qQdO3Zo/fr1ampq0p133qm2trZu96+srFQgEIhseXl58R4JANAHxT1AZWVluu+++zRhwgSVlJTovffe08mTJ/Xmm292u39FRYVCoVBka25ujvdIAIA+KOGfDkhPT9fNN9+sxsbGbp/3+/3y+/2JHgMA0Mck/OeATp06pcOHDysnJyfRhwIAJJG4B+ixxx5TTU2NPv30U/3xj3/U7NmzNXDgQM2fPz/ehwIAJLG4/xXc559/rvnz5+vEiRMaNmyY7rjjDtXV1WnYsGHxPhQAIInFPUCvv/56vL8lrnId/zDJ85qDs9fGdKzBvoGe10z0H/e8ZvuqTz2vCVV5XgL0adwLDgBgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwkfBfSAd808D0gOc19z23w/OaU67T8xpJ+tEb/9PzmmWl3ud7Lf+/PK8pnbbY85pBVfWe1wC9hSsgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBu2OhVf92S6XnN4sAuz2u+X+f9ztGSNPrROs9rXuoo87ymfMG/eF4z6BetnteEs37oeY0kpW3xfh4Ar7gCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNS9Kql+TW9cpzgS9f0ynEkaXTlQe+LFnhf8t7Y//C85i+/Oe39QJKWvD/b85rzX3wR07Fw9eIKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1IgX4sZ+CQmNZ1jh3uec0AbkYKj7gCAgCYIEAAABOeA7R7927NmDFDubm58vl82rZtW9Tzzjk988wzysnJ0ZAhQ1RcXKxDhw7Fa14AQD/hOUDt7e0qKCjQunXrun1+zZo1evHFF7Vhwwbt2bNH1113nUpKSnTmzJkrHhYA0H94/hBCWVmZysrKun3OOacXXnhBTz31lGbOnClJevXVV5Wdna1t27Zp3rx5VzYtAKDfiOt7QE1NTWppaVFxcXHksUAgoMLCQtXW1na7pqOjQ+FwOGoDAPR/cQ1QS0uLJCk7Ozvq8ezs7MhzF6usrFQgEIhseXl58RwJANBHmX8KrqKiQqFQKLI1NzdbjwQA6AVxDVAwGJQktba2Rj3e2toaee5ifr9faWlpURsAoP+La4Dy8/MVDAZVVVUVeSwcDmvPnj0qKiqK56EAAEnO86fgTp06pcbGxsjXTU1N2r9/vzIyMjRixAgtX75cv/rVr3TTTTcpPz9fTz/9tHJzczVr1qx4zg0ASHKeA7R3717dfffdka9XrFghSVqwYIE2bdqkJ554Qu3t7Vq8eLFOnjypO+64Qzt27NA111wTv6kBAEnPc4CmTp0q51yPz/t8Pq1evVqrV6++osGAZOHOnvW85rW2HM9rfpra/SdJEyHl0FHPa84lYA70b+afggMAXJ0IEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwvPdsIEr8U//fp/nNfMf/BfPa74c7/e8RpKCVZff52Kuo8Pzmk1HfuR5zU9vfdvzmsdbCj2vkaTzJ/4a0zrAC66AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwUvWrkf572vKZz4XnPa3Y++pznNZI0/x/ne17z6cFcz2s23rjB85pYfBLKjmmd6/xLnCcBLsUVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRolf5av+P5zXjP/gfntd88uN/87xGknbcstX7oltiOlQMfJ5XNH0xNKYjfVfcjBSJxxUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5Giz7vxp/s8r7lrbnlMxzo+yfua84Hzntfc8JH3f/U+enq95zXzxtZ7XiNJf7om1fOarjNnYjoWrl5cAQEATBAgAIAJzwHavXu3ZsyYodzcXPl8Pm3bti3q+YULF8rn80VtpaWl8ZoXANBPeA5Qe3u7CgoKtG7duh73KS0t1bFjxyLbli1brmhIAED/4/md0LKyMpWVlX3rPn6/X8FgMOahAAD9X0LeA6qurlZWVpbGjBmjpUuX6sSJEz3u29HRoXA4HLUBAPq/uAeotLRUr776qqqqqvSb3/xGNTU1Kisr0/nz3X9UtbKyUoFAILLl5eXFeyQAQB8U958DmjdvXuTP48eP14QJEzR69GhVV1dr2rRpl+xfUVGhFStWRL4Oh8NECACuAgn/GPaoUaOUmZmpxsbGbp/3+/1KS0uL2gAA/V/CA/T555/rxIkTysnJSfShAABJxPNfwZ06dSrqaqapqUn79+9XRkaGMjIytGrVKs2ZM0fBYFCHDx/WE088oRtvvFElJSVxHRwAkNw8B2jv3r26++67I19//f7NggULtH79eh04cEC/+93vdPLkSeXm5mr69On65S9/Kb/fH7+pAQBJz+ecc9ZDfFM4HFYgENBUzdQg32DrcYA+472/fOR5TZdi+9d71sR7PK8519Ia07HQ/5xznarWdoVCoW99X597wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBE3H8lN4Dkd+Qnoz2vyf1n7oYNb7gCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSIEms/nK85zVPZR6I6Vhf3XY6pnWAF1wBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpkCTe+Wyc5zWx3oz0R/n/z/Oa1piOhKsZV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRgokifNVQ70vmhjbsYalnPK85vjgFM9rXOdZz2vQf3AFBAAwQYAAACY8BaiyslKTJk1SamqqsrKyNGvWLDU0NETtc+bMGZWXl2vo0KG6/vrrNWfOHLW28ptCAADRPAWopqZG5eXlqqur086dO9XZ2anp06ervb09ss8jjzyid955R2+99ZZqamp09OhR3XvvvXEfHACQ3Dx9CGHHjh1RX2/atElZWVmqr6/XlClTFAqF9PLLL2vz5s368Y9/LEnauHGjbrnlFtXV1emHP/xh/CYHACS1K3oPKBQKSZIyMjIkSfX19ers7FRxcXFkn7Fjx2rEiBGqra3t9nt0dHQoHA5HbQCA/i/mAHV1dWn58uW6/fbbNW7chd9V39LSopSUFKWnp0ftm52drZaWlm6/T2VlpQKBQGTLy8uLdSQAQBKJOUDl5eU6ePCgXn/99SsaoKKiQqFQKLI1Nzdf0fcDACSHmH4QddmyZXr33Xe1e/duDR8+PPJ4MBjU2bNndfLkyairoNbWVgWDwW6/l9/vl9/vj2UMAEAS83QF5JzTsmXLtHXrVu3atUv5+flRz0+cOFGDBw9WVVVV5LGGhgYdOXJERUVF8ZkYANAveLoCKi8v1+bNm7V9+3alpqZG3tcJBAIaMmSIAoGAHnroIa1YsUIZGRlKS0vTww8/rKKiIj4BBwCI4ilA69evlyRNnTo16vGNGzdq4cKFkqTf/va3GjBggObMmaOOjg6VlJTopZdeisuwAID+w+ecc9ZDfFM4HFYgENBUzdQg32DrcYA+Y1Aw2/Oajf/77ZiOdcOAazyv+cE/P+x5TfC3f/S8Bn3fOdepam1XKBRSWlpaj/txLzgAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYiOk3ogLofedaWj2v+be/3hbTsR4f+rHnNacnnfa8xjfI+3+CfCkpntd0nfY+GxKPKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3IwX6sVf+6+6Y1j0+3/vNSD++62XPa8a8vMjzmhsyTnlekznj/3peg8TjCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSIF+bMzav8S0bm3pTZ7XPHzDIc9rGor/1fOaB5qme14T8rwCvYErIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjBfqxc581x7Tuf41L875GE2M6lncneuk4SDSugAAAJggQAMCEpwBVVlZq0qRJSk1NVVZWlmbNmqWGhoaofaZOnSqfzxe1LVmyJK5DAwCSn6cA1dTUqLy8XHV1ddq5c6c6Ozs1ffp0tbe3R+23aNEiHTt2LLKtWbMmrkMDAJKfpw8h7NixI+rrTZs2KSsrS/X19ZoyZUrk8WuvvVbBYDA+EwIA+qUreg8oFLrwi24zMjKiHn/ttdeUmZmpcePGqaKiQqdPn+7xe3R0dCgcDkdtAID+L+aPYXd1dWn58uW6/fbbNW7cuMjj999/v0aOHKnc3FwdOHBATz75pBoaGvT22293+30qKyu1atWqWMcAACQpn3POxbJw6dKl+v3vf68PP/xQw4cP73G/Xbt2adq0aWpsbNTo0aMveb6jo0MdHR2Rr8PhsPLy8jRVMzXINziW0QAAhs65TlVru0KhkNLSev6ZspiugJYtW6Z3331Xu3fv/tb4SFJhYaEk9Rggv98vv98fyxgAgCTmKUDOOT388MPaunWrqqurlZ+ff9k1+/fvlyTl5OTENCAAoH/yFKDy8nJt3rxZ27dvV2pqqlpaWiRJgUBAQ4YM0eHDh7V582bdc889Gjp0qA4cOKBHHnlEU6ZM0YQJExLyDwAASE6e3gPy+XzdPr5x40YtXLhQzc3N+slPfqKDBw+qvb1deXl5mj17tp566qlv/XvAbwqHwwoEArwHBABJKiHvAV2uVXl5eaqpqfHyLQEAVynuBQcAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMDHIeoCLOeckSefUKTnjYQAAnp1Tp6S//fe8J30uQG1tbZKkD/We8SQAgCvR1tamQCDQ4/M+d7lE9bKuri4dPXpUqamp8vl8Uc+Fw2Hl5eWpublZaWlpRhPa4zxcwHm4gPNwAefhgr5wHpxzamtrU25urgYM6Pmdnj53BTRgwAANHz78W/dJS0u7ql9gX+M8XMB5uIDzcAHn4QLr8/BtVz5f40MIAAATBAgAYCKpAuT3+7Vy5Ur5/X7rUUxxHi7gPFzAebiA83BBMp2HPvchBADA1SGproAAAP0HAQIAmCBAAAATBAgAYCJpArRu3Tp997vf1TXXXKPCwkL96U9/sh6p1z377LPy+XxR29ixY63HSrjdu3drxowZys3Nlc/n07Zt26Ked87pmWeeUU5OjoYMGaLi4mIdOnTIZtgEutx5WLhw4SWvj9LSUpthE6SyslKTJk1SamqqsrKyNGvWLDU0NETtc+bMGZWXl2vo0KG6/vrrNWfOHLW2thpNnBh/z3mYOnXqJa+HJUuWGE3cvaQI0BtvvKEVK1Zo5cqV+uijj1RQUKCSkhIdP37cerRed+utt+rYsWOR7cMPP7QeKeHa29tVUFCgdevWdfv8mjVr9OKLL2rDhg3as2ePrrvuOpWUlOjMmTO9PGliXe48SFJpaWnU62PLli29OGHi1dTUqLy8XHV1ddq5c6c6Ozs1ffp0tbe3R/Z55JFH9M477+itt95STU2Njh49qnvvvddw6vj7e86DJC1atCjq9bBmzRqjiXvgksDkyZNdeXl55Ovz58+73NxcV1lZaThV71u5cqUrKCiwHsOUJLd169bI111dXS4YDLrnnnsu8tjJkyed3+93W7ZsMZiwd1x8HpxzbsGCBW7mzJkm81g5fvy4k+Rqamqccxf+tx88eLB76623Ivv8+c9/dpJcbW2t1ZgJd/F5cM65u+66y/385z+3G+rv0OevgM6ePav6+noVFxdHHhswYICKi4tVW1trOJmNQ4cOKTc3V6NGjdIDDzygI0eOWI9kqqmpSS0tLVGvj0AgoMLCwqvy9VFdXa2srCyNGTNGS5cu1YkTJ6xHSqhQKCRJysjIkCTV19ers7Mz6vUwduxYjRgxol+/Hi4+D1977bXXlJmZqXHjxqmiokKnT5+2GK9Hfe5mpBf78ssvdf78eWVnZ0c9np2drU8++cRoKhuFhYXatGmTxowZo2PHjmnVqlW68847dfDgQaWmplqPZ6KlpUWSun19fP3c1aK0tFT33nuv8vPzdfjwYf3iF79QWVmZamtrNXDgQOvx4q6rq0vLly/X7bffrnHjxkm68HpISUlRenp61L79+fXQ3XmQpPvvv18jR45Ubm6uDhw4oCeffFINDQ16++23DaeN1ucDhL8pKyuL/HnChAkqLCzUyJEj9eabb+qhhx4ynAx9wbx58yJ/Hj9+vCZMmKDRo0erurpa06ZNM5wsMcrLy3Xw4MGr4n3Qb9PTeVi8eHHkz+PHj1dOTo6mTZumw4cPa/To0b09Zrf6/F/BZWZmauDAgZd8iqW1tVXBYNBoqr4hPT1dN998sxobG61HMfP1a4DXx6VGjRqlzMzMfvn6WLZsmd5991198MEHUb++JRgM6uzZszp58mTU/v319dDTeehOYWGhJPWp10OfD1BKSoomTpyoqqqqyGNdXV2qqqpSUVGR4WT2Tp06pcOHDysnJ8d6FDP5+fkKBoNRr49wOKw9e/Zc9a+Pzz//XCdOnOhXrw/nnJYtW6atW7dq165dys/Pj3p+4sSJGjx4cNTroaGhQUeOHOlXr4fLnYfu7N+/X5L61uvB+lMQf4/XX3/d+f1+t2nTJvfxxx+7xYsXu/T0dNfS0mI9Wq969NFHXXV1tWtqanJ/+MMfXHFxscvMzHTHjx+3Hi2h2tra3L59+9y+ffucJPf888+7ffv2uc8++8w559yvf/1rl56e7rZv3+4OHDjgZs6c6fLz891XX31lPHl8fdt5aGtrc4899pirra11TU1N7v3333e33Xabu+mmm9yZM2esR4+bpUuXukAg4Kqrq92xY8ci2+nTpyP7LFmyxI0YMcLt2rXL7d271xUVFbmioiLDqePvcuehsbHRrV692u3du9c1NTW57du3u1GjRrkpU6YYTx4tKQLknHNr1651I0aMcCkpKW7y5Mmurq7OeqReN3fuXJeTk+NSUlLcd77zHTd37lzX2NhoPVbCffDBB07SJduCBQuccxc+iv3000+77Oxs5/f73bRp01xDQ4Pt0Anwbefh9OnTbvr06W7YsGFu8ODBbuTIkW7RokX97v+kdffPL8lt3Lgxss9XX33lfvazn7kbbrjBXXvttW727Nnu2LFjdkMnwOXOw5EjR9yUKVNcRkaG8/v97sYbb3SPP/64C4VCtoNfhF/HAAAw0effAwIA9E8ECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIn/D9TwnCIHGkHqAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 15. Show a sample from the mnist dataset (incorrect prediction)\n",
        "image_to_show = 264\n",
        "from_group = 'test' # 'train' or 'test'\n",
        "if from_group == 'train':\n",
        "    plt.imshow(X_train[image_to_show])\n",
        "    print('Ground truth label: ',Y_train[image_to_show])\n",
        "else:\n",
        "    plt.imshow(X_test[image_to_show])\n",
        "    print('Ground truth label: ',Y_test[image_to_show])\n",
        "    if len(predict_x)>image_to_show:\n",
        "        print('Predicted label: ',classes_x[image_to_show])"
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}